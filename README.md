# Assignment2

## Задача №1
**Гетерогенная параллелизация** — это подход, когда в одной задаче одновременно (или по этапам) используются разные вычислительные устройства с разной архитектурой, чаще всего CPU + GPU (иногда ещё FPGA/TPU). Идея: отдать CPU то, где важна сложная логика и ветвления, а GPU — массовые однотипные вычисления над большими данными.

### 1) Различия параллельных вычислений на CPU и GPU

CPU: мало “тяжёлых” ядер, сильные ядра, большие кэши, хорошо переносит ветвления, рекурсию, сложные структуры данных. Подходит для “разных” задач, где потоки выполняют разные ветки кода.

GPU: очень много “легких” ядер/потоков, упор в пропускную способность, выигрывает на одинаковых операциях над массивами. Плохо переносит сильную дивергенцию ветвлений (когда разные потоки идут по разным if), любит “плотную” математику и регулярный доступ к памяти.

### 2) Преимущества гетерогенной параллелизации

- Скорость: тяжёлые массовые этапы (фильтры, матрицы, свёртки, сортировки/редукции) уезжают на GPU.

- Энергоэффективность: GPU часто даёт больше операций на ватт для data-parallel задач.

- Гибкость: CPU управляет, готовит данные, решает нерегулярные части, GPU “молотит” регулярные.

### 3) Примеры реальных приложений

#### Машинное обучение (CPU+GPU)
- PyTorch
- TensorFlow
- JAX
- XGBoost (есть GPU-ускорение)
- LightGBM (есть GPU-ускорение)
- ONNX Runtime (поддерживает разные аппаратные бэкенды)

#### Научные расчёты / симуляции (HPC)
- GROMACS (молекулярная динамика, активно использует GPU)
- LAMMPS (молекулярная динамика, есть GPU-пакеты)
- NAMD (молекулярная динамика, GPU-ускорение)
- AMBER (MD, GPU-ускорение)
- OpenFOAM (CFD; часто CPU, но есть GPU-направления/сборки и гетерогенные пайплайны в проектах вокруг него)
- ANSYS Fluent (коммерческий CFD, поддержка GPU для ряда задач/солверов)
- COMSOL Multiphysics (в ряде конфигураций/лицензий — ускорение через GPU/акселераторы)
- LS-DYNA (явная динамика, есть GPU-опции)
- VASP (квантово-химические расчёты; есть версии/сборки с GPU-ускорением в HPC-практике)

#### Рендеринг / графика / 3D
- Blender (Cycles рендер на GPU, сцена/логика на CPU)
- Autodesk Arnold (есть GPU-рендер)
- V-Ray (GPU-рендер)
- OctaneRender (GPU-рендер)

#### Видео/изображения (медиа-пайплайны CPU+GPU)
- FFmpeg (через NVENC/NVDEC, CUDA-фильтры, VAAPI/Quick Sync — типичный гетерогенный пайплайн)
- DaVinci Resolve (массово грузит GPU: цвет, эффекты, AI-инструменты)
- Adobe Premiere Pro (GPU-ускорение эффектов/кодирования)
- Adobe After Effects (часть эффектов/рендера с GPU)
- Adobe Photoshop (GPU для фильтров/нейрофункций)

#### Компьютерное зрение / робототехника
- OpenCV (CUDA/OpenCL-модули)
- NVIDIA DeepStream (видеoаналитика: декод на GPU + инференс на GPU, управление на CPU)

#### Базы/аналитика/Big Data (часто CPU+GPU)
- RAPIDS (cuDF, cuML, cuGraph — GPU-аналитика, orchestration на CPU)
- Apache Spark с NVIDIA RAPIDS Accelerator for Apache Spark (Spark-пайплайн + GPU-ускорение)

--------------------------------------------------------------------------------------------------
## Задача №2
Создание массива, содержащего 10 000 случайных чисел.
Определение минимального и максимального элементов:
- последовательным методом;
- параллельным методом с применением OpenMP.

Сравнение времени выполнения последовательной и параллельной реализаций.

Вывод:

```
Sequential Min: 34, Max: 99988  
Parallel   Min: 34, Max: 99988  
Sequential time: 49 microseconds
Parallel time:   80 microseconds 
```

--------------------------------------------------------------------------------------------------
## Задача №3

Реализация параллельной сортировки выбором с использованием OpenMP.
В работе реализованы последовательный алгоритм сортировки выбором и его параллельная версия на основе OpenMP.
Проведено тестирование производительности для массивов размером 1000 и 10000 элементов.

Вывод: 

```
Array size: 1000     
Sequential time: 2 ms
Parallel time: 1 ms  

Array size: 10000      
Sequential time: 209 ms
Parallel time: 128 ms  
```

--------------------------------------------------------------------------------------------------
## Задача №4

Реализация сортировки на GPU с применением CUDA.
Массив данных разбивается на несколько подмассивов, каждый из которых обрабатывается отдельным блоком GPU.
Сортировка подмассивов выполняется параллельно на графическом процессоре.
Производится измерение времени выполнения CUDA-ядра и анализ эффективности параллельной обработки.

Вывод: 

```
Array size: 1000
Sequential time: 1 ms
Parallel time:   68 ms

Array size: 10000
Sequential time: 99 ms
Parallel time:   5091 ms
```
--------------------------------------------------------------------------------------------------

## Контрольные вопросы к Assignment 2

### 1. Что понимается под гетерогенной параллелизацией?
Гетерогенная параллелизация представляет собой метод организации вычислений, при котором в одной программе совместно используются разные типы вычислительных устройств, такие как центральный и графический процессоры, каждый из которых выполняет задачи, наиболее соответствующие его возможностям.

### 2. В чём принципиальные различия архитектур CPU и GPU?
CPU ориентирован на выполнение последовательных и логически сложных операций и содержит ограниченное число высокопроизводительных универсальных ядер. GPU, напротив, включает большое количество более простых вычислительных ядер и оптимизирован для одновременной обработки большого объёма однотипных данных.

### 3. Какие типы задач лучше подходят для выполнения на GPU, а какие — на CPU?
GPU наиболее эффективно используется для задач с высокой степенью параллелизма, например обработки массивов данных, матричных вычислений, а также работы с графикой и видео. CPU предпочтительнее применять для задач управления программным потоком, обработки ветвлений, операций ввода-вывода и реализации сложной логики.

### 4. Почему не все алгоритмы эффективно распараллеливаются с использованием OpenMP?
Эффективность распараллеливания ограничивается наличием зависимостей между данными, последовательных участков кода и критических секций, которые уменьшают возможный уровень параллелизма и снижают выигрыш от использования OpenMP.

### 5. В чём заключается основная идея алгоритма сортировки слиянием?
Сортировка слиянием основана на принципе «разделяй и властвуй»: исходный массив рекурсивно разбивается на более мелкие части, которые сортируются отдельно, после чего объединяются в единый упорядоченный массив.

### 6. Какие сложности возникают при реализации сортировки слиянием на GPU?
К основным трудностям относятся организация эффективной синхронизации потоков, реализация параллельного этапа слияния, а также управление памятью и минимизация задержек при доступе к данным на GPU.

### 7. Как выбор размера блока и сетки влияет на производительность вычислений на GPU?
Неподходящие параметры блоков и сетки могут привести либо к неэффективному использованию вычислительных ресурсов GPU, либо к росту накладных расходов, что в итоге снижает общую производительность приложения.

### 8. Почему гетерогенный подход может быть эффективнее использования только CPU или только GPU?
Использование гетерогенного подхода позволяет задействовать сильные стороны как CPU, так и GPU, распределяя между ними задачи оптимальным образом, что способствует более рациональному использованию ресурсов и повышению производительности вычислений.
